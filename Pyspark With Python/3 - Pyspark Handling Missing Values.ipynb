{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdaf133",
   "metadata": {},
   "source": [
    "# Pyspark Handling Missing Values\n",
    "\n",
    "- Dropping NaN values\n",
    "- Dropping Rows\n",
    "- Various Parameter In Dropping functionalities\n",
    "- Handling Missing values by Mean, Median And Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12426673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Practice\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c509426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----------+------+\n",
      "|        Name| age|Experience|Salary|\n",
      "+------------+----+----------+------+\n",
      "|      Younes|  31|        10| 30000|\n",
      "|      Mourad|  30|         8| 25000|\n",
      "|Fatima Zahra|  29|         4| 20000|\n",
      "|     M'hamed|  24|         3| 20000|\n",
      "|       Fdila|  21|         1| 15000|\n",
      "|       Hamid|  23|         2| 18000|\n",
      "|        NULL|NULL|      NULL|  NULL|\n",
      "|         Ali|NULL|      NULL| 40000|\n",
      "|        NULL|  34|        10| 38000|\n",
      "|       Zineb|  36|      NULL|  NULL|\n",
      "+------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reading the dataset\n",
    "df_pyspark = spark.read.csv(\"test2.csv\", header=True, inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5bc5a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+----------+------+\n",
      "|        Name|age|Experience|Salary|\n",
      "+------------+---+----------+------+\n",
      "|      Younes| 31|        10| 30000|\n",
      "|      Mourad| 30|         8| 25000|\n",
      "|Fatima Zahra| 29|         4| 20000|\n",
      "|     M'hamed| 24|         3| 20000|\n",
      "|       Fdila| 21|         1| 15000|\n",
      "|       Hamid| 23|         2| 18000|\n",
      "+------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropping all the rows that contain at least 1 NULL (how =\"any\" by default)\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f6a5aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----------+------+\n",
      "|        Name| age|Experience|Salary|\n",
      "+------------+----+----------+------+\n",
      "|      Younes|  31|        10| 30000|\n",
      "|      Mourad|  30|         8| 25000|\n",
      "|Fatima Zahra|  29|         4| 20000|\n",
      "|     M'hamed|  24|         3| 20000|\n",
      "|       Fdila|  21|         1| 15000|\n",
      "|       Hamid|  23|         2| 18000|\n",
      "|         Ali|NULL|      NULL| 40000|\n",
      "|        NULL|  34|        10| 38000|\n",
      "|       Zineb|  36|      NULL|  NULL|\n",
      "+------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropping rows that contain only NULL values\n",
    "df_pyspark.na.drop(how =\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6af84e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----------+------+\n",
      "|        Name| age|Experience|Salary|\n",
      "+------------+----+----------+------+\n",
      "|      Younes|  31|        10| 30000|\n",
      "|      Mourad|  30|         8| 25000|\n",
      "|Fatima Zahra|  29|         4| 20000|\n",
      "|     M'hamed|  24|         3| 20000|\n",
      "|       Fdila|  21|         1| 15000|\n",
      "|       Hamid|  23|         2| 18000|\n",
      "|         Ali|NULL|      NULL| 40000|\n",
      "|        NULL|  34|        10| 38000|\n",
      "|       Zineb|  36|      NULL|  NULL|\n",
      "+------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Threshold :  drop rows that have less than `thresh` non-null values\n",
    "df_pyspark.na.drop(thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91598b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----------+------+\n",
      "|        Name| age|Experience|Salary|\n",
      "+------------+----+----------+------+\n",
      "|      Younes|  31|        10| 30000|\n",
      "|      Mourad|  30|         8| 25000|\n",
      "|Fatima Zahra|  29|         4| 20000|\n",
      "|     M'hamed|  24|         3| 20000|\n",
      "|       Fdila|  21|         1| 15000|\n",
      "|       Hamid|  23|         2| 18000|\n",
      "|         Ali|NULL|      NULL| 40000|\n",
      "|        NULL|  34|        10| 38000|\n",
      "+------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# subset argument : subset : str, tuple or list, optional optional list of column names to consider.\n",
    "df_pyspark.na.drop(how='any', subset=['Salary']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bea86ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+----------+------+\n",
      "|          Name|age|Experience|Salary|\n",
      "+--------------+---+----------+------+\n",
      "|        Younes| 31|        10| 30000|\n",
      "|        Mourad| 30|         8| 25000|\n",
      "|  Fatima Zahra| 29|         4| 20000|\n",
      "|       M'hamed| 24|         3| 20000|\n",
      "|         Fdila| 21|         1| 15000|\n",
      "|         Hamid| 23|         2| 18000|\n",
      "|Missing Values|  0|      NULL|  NULL|\n",
      "|           Ali|  0|      NULL| 40000|\n",
      "|Missing Values| 34|        10| 38000|\n",
      "|         Zineb| 36|      NULL|  NULL|\n",
      "+--------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filling the missing values\n",
    "df_pyspark.na.fill({'Name':'Missing Values',\n",
    "                    'age' : 0}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e509776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----------+------+\n",
      "|        Name| age|Experience|Salary|\n",
      "+------------+----+----------+------+\n",
      "|      Younes|  31|        10| 30000|\n",
      "|      Mourad|  30|         8| 25000|\n",
      "|Fatima Zahra|  29|         4| 20000|\n",
      "|     M'hamed|  24|         3| 20000|\n",
      "|       Fdila|  21|         1| 15000|\n",
      "|       Hamid|  23|         2| 18000|\n",
      "|        NULL|NULL|      NULL|  NULL|\n",
      "|         Ali|NULL|      NULL| 40000|\n",
      "|        NULL|  34|        10| 38000|\n",
      "|       Zineb|  36|      NULL|  NULL|\n",
      "+------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d89fec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----------+------+\n",
      "|        Name| age|Experience|Salary|\n",
      "+------------+----+----------+------+\n",
      "|      Younes|  31|        10| 30000|\n",
      "|      Mourad|  30|         8| 25000|\n",
      "|Fatima Zahra|  29|         4| 20000|\n",
      "|     M'hamed|  24|         3| 20000|\n",
      "|       Fdila|  21|         1| 15000|\n",
      "|       Hamid|  23|         2| 18000|\n",
      "|        NULL|NULL|      NULL|  NULL|\n",
      "|         Ali|NULL|      NULL| 40000|\n",
      "|        NULL|  34|        10| 38000|\n",
      "|       Zineb|  36|      NULL|  NULL|\n",
      "+------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34dcb5",
   "metadata": {},
   "source": [
    "Filling the missing values in acolumn with the mean (or median or mode) value of that column, for that we use an `Imputer` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62bef213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['age', 'Experience', 'Salary'], \n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
    "    ).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "250262dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----+----------+------+-----------+------------------+--------------+\n",
      "|        Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+------------+----+----------+------+-----------+------------------+--------------+\n",
      "|      Younes|  31|        10| 30000|         31|                10|         30000|\n",
      "|      Mourad|  30|         8| 25000|         30|                 8|         25000|\n",
      "|Fatima Zahra|  29|         4| 20000|         29|                 4|         20000|\n",
      "|     M'hamed|  24|         3| 20000|         24|                 3|         20000|\n",
      "|       Fdila|  21|         1| 15000|         21|                 1|         15000|\n",
      "|       Hamid|  23|         2| 18000|         23|                 2|         18000|\n",
      "|        NULL|NULL|      NULL|  NULL|         28|                 5|         25750|\n",
      "|         Ali|NULL|      NULL| 40000|         28|                 5|         40000|\n",
      "|        NULL|  34|        10| 38000|         34|                10|         38000|\n",
      "|       Zineb|  36|      NULL|  NULL|         36|                 5|         25750|\n",
      "+------------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e448f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
